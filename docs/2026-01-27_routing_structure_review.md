# 프로젝트 에이전트 라우팅 구조 진단 및 개선 방안

## 개요

본 문서는 시니어로부터 받은 라우팅 구조 진단 및 개선 제안을 정리하고, 실제 코드와 비교 분석한 내용입니다.

---

## 1. 시니어 진단 내용

주의: 본 섹션은 시니어 진단 원문 요약이며, 현재 코드와 일부 가정이 다를 수 있습니다. 실제 코드 기준 정정은 2장에서 다룹니다.

### 1.1 현재 라우팅 전략과 구조 개요

프로젝트의 에이전트는 RAG(Retrieval-Augmented Generation) 기반으로 반도체 공정 트러블슈팅을 지원합니다. 사용자의 입력 질문을 LLM을 통해 **의도 분류(intent classification)**하여 미리 정의된 경로로 라우팅하는 구조입니다. 현재 분류되는 카테고리는 다음 네 가지입니다.

1. 일반적인 질문 – 에이전트 자체나 일상적 대화 (예: "너는 누구니?", "오늘 날씨 어때?" 등)
2. 데이터 조회 요청 – DB나 시스템에서 정보를 조회하는 질의 (예: "설치된 장비 수가 몇 대인가?", "지난달 고장 이력 알려줘")
3. Trouble-Shooting 질문 – 장비 오류나 문제 해결에 대한 전문 질의
4. 장비 설치 방법 질문 – 장비 설치 절차나 방법에 대한 질의

LLM 분류 결과에 따라 1번은 일반 챗봇 응답 생성, 2번은 데이터베이스 쿼리 수행, 3번은 트러블슈팅 관련 문서 검색(RAG) 후 답변, 4번은 설치 매뉴얼 검색 후 답변 등으로 라우팅됩니다. 이렇게 전용 프롬프트와 지식베이스를 각 카테고리에 맞춰 활용하는 멀티프롬프트 체인을 구성한 것으로 보입니다 (예: 일반질문은 캐주얼 톤 프롬프트, 전문질문은 도메인 전문가 프롬프트 등). 분류와 라우팅은 주로 LLM의 zero-shot 분류 능력에 의존하고 있으며, LangChain의 RouterChain이나 유사한 로직으로 구현되었을 가능성이 높습니다.

### 1.2 발생한 문제: LLM 기반 라우팅의 오분류 현상

현재 LLM 기반 라우팅이 오작동하여 사용자 질의가 잘못된 경로로 분류되는 문제가 보고되었습니다. 대표적으로 "너는 누구니" 같은 일반 질문조차 TS(Trouble-Shooting) 카테고리로 잘못 분류되고 있습니다. 이는 의도 분류 단계의 오류로, 라우터가 평문 질의를 정확히 해석하지 못하고 도메인 질문으로 오인하는 현상입니다. 그 결과 사용자는 엉뚱하게 트러블슈팅 흐름의 응답(예: 전문용어가 담긴 답변이나 문제해결 절차)을 받게 되어 사용자 경험 저하로 이어집니다.

이러한 LLM 분류의 불안정성은 업계에서도 지적되는 부분입니다. 한 OpenAI 포럼 사용자는 "plain intent classification with LLM does not work and is not consistent" (LLM을 이용한 단순 의도 분류는 잘 작동하지 않으며 일관성이 없다)고 언급했고, 이를 해결하려면 프롬프트를 치밀하게 설계하여 모호함을 줄여야 한다고 조언했습니다. 현재 에이전트의 분류 프롬프트나 로직이 이러한 모호함을 충분히 제거하지 못해 LLM이 엉뚱한 카테고리를 선택하는 것으로 보입니다. 특히 카테고리 3과 4 (트러블슈팅 vs 설치법)은 도메인 지식이라는 공통점 때문에 경계가 모호한데, LLM이 이 둘을 구분하지 못하고 한쪽으로 치우치는 경향이 있습니다. 심지어 "너는 누구니" 같은 문맥상 일반 대화도, LLM은 현재 시스템 프롬프트 영향으로 전문 질문으로 오인하고 있습니다.

### 1.3 시스템 프롬프트 및 라우팅 로직의 구조적 이슈

오분류의 원인을 살펴보면, 시스템 프롬프트 설계와 라우팅 로직 구조에 몇 가지 문제가 내포되어 있습니다.

**첫째, 시스템 프롬프트의 편향 문제입니다.** 분류를 위해 LLM에 주어진 시스템 프롬프트가 도메인 전문 지식에 치중되어 있을 가능성이 높습니다. 예를 들어 "당신은 반도체 공정 문제 해결을 돕는 AI입니다..."와 같이 에이전트의 역할을 강조한 프롬프트가 항상 주어지는 경우, 모델은 사용자의 모든 질문을 해당 맥락에서 해석하려 합니다. 그 결과 일반적인 질문까지도 반도체 문제 맥락으로 과대 해석해서 TS 카테고리로 분류할 수 있습니다. 시스템 메시지는 모델의 거동을 강력히 좌우하므로, 너무 한쪽 분야로 치우친 지시만 있으면 모델의 편향된 응답을 유도합니다. 현재 분류 프롬프트가 "사용자 질문을 4가지 중 하나로 분류해"라는 지시는 있겠지만, 일반적 대화에 대한 명시적 지침이나 예시가 부족했을 수 있습니다.

**둘째, 라우팅 로직의 구현 방식입니다.** 분류를 LLM에게 맡기는 구조에서는, 모델 출력이 일관된 포맷으로 나오도록 강제하지 않으면 오동작 여지가 큽니다. 예를 들어 카테고리 이름만 딱 출력하게 하지 않고 장황한 설명과 함께 나오게 두면, 파싱 로직이 혼란을 겪거나 키워드 오검출로 잘못된 분류를 할 수 있습니다. (예: 모델이 "이 질문은 일반적인 것이며 트러블슈팅과 관련 없습니다."라고 답하면, 응답에 "트러블슈팅" 단어가 포함되었다는 이유로 잘못 TS로 해석하는 식의 버그). 따라서 LLM 출력 포맷을 간결히 제한하고, 파싱 로직에도 예외 처리를 넣어야 합니다. 현재 라우팅 모듈이 이러한 대비가 부족했을 수 있습니다.

또한 LLM 라우팅 자체가 구조적으로 비결정적이고 예측 불가한 면이 있습니다. Zep 팀의 보고에 따르면 LLM을 의도 라우팅에 사용하면 응답 지연이나 가변적인 결과로 신뢰하기 어렵다고 합니다. 이처럼 LLM 호출에 의존한 분기는 시스템 응답 지연이나 실수로 이어질 수 있으며, 특히 분류 결과에 따라 완전히 다른 체인이 실행되는 구조에서는 한 번의 분류 오류로 전체인의 품질이 악화됩니다. 현재 구조도 이러한 LLM 분류에 단일 의존점이 있어, 분류 오류 시 복구가 어렵고 곧장 잘못된 경로를 타게 됩니다.

**셋째, 카테고리 설계의 세분화입니다.** 현재 3번 TS와 4번 설치방법은 모두 전문 도메인 지식 질의로 분류되지만, LLM 입장에서는 두 카테고리의 경계가 명확하지 않습니다. "장비 온도 센서 고장 원인?"과 "장비 온도 센서 설치 방법?"은 질문 형태만 약간 다를 뿐 모두 전문 용어가 포함되어 있습니다. LLM이 완벽히 이해하지 못하면 두 상황을 혼동할 수 있고, 현재 시스템에서는 이 경우 TS로 치우쳐 분류되는 모습입니다. 분류 기준이 사람에게는 분명해 보여도 모델에게는 애매할 수 있다는 점을 간과한 것으로 보입니다. 특히 LLM은 훈련 데이터에 없는 세밀한 카테고리 구분을 요구받으면 실수가 잦아집니다. Zero-shot 분류에서 클래스들이 모호하거나 모델의 사전 지식에 없으면 성능이 급격히 떨어지는 것으로 알려져 있으며, 현재 TS vs 설치방법 구분이 그 사례로 보입니다.

**넷째, 컨텍스트 흐름 관리 미흡입니다.** 에이전트가 멀티턴 대화로 설계되어 이전 Q&A 맥락을 메모리로 유지하고 있다면, 새로운 질문 분류 시 이 대화 맥락이 영향을 주는지 살펴봐야 합니다. 만약 사용자가 바로 전에 트러블슈팅 질문을 했고, 그에 대한 답변까지 주어진 상황에서 곧바로 "너는 누구니"라고 물었다면, LLM은 이전 대화 맥락상 사용자가 에이전트의 정체를 캐묻는 의도가 아니라 트러블슈팅 맥락에서의 "너" (예: 어떤 모듈? 어떤 담당자?)를 묻는 것으로 오해했을 수 있습니다. 이는 사람에겐 말이 안 되지만, 대화 맥락을 맹목적으로 포함하면 LLM이 문맥을 이어 붙여 잘못된 추론을 할 가능성이 있습니다. 따라서 의도 분류시에는 해당 턴의 질문만 독립적으로 검토해야 하고, 불필요한 이전 대화는 제외하거나, 이전 맥락을 참고하더라도 주제 전환(topic switch)을 인지하도록 해야 합니다. 현재 구조에서는 이러한 컨텍스트 관리가 부족해, 이전 턴의 TS 맥락 때문에 모델이 새 질문도 TS로 착각했을 여지가 있습니다.

요약하면, 분류 프롬프트가 일반 질의에 대한 대응을 누락하고 도메인 맥락만 강조한 점, LLM 출력 처리의 허술함, 세분된 클래스 설계, 문맥 처리의 미비 등이 복합적으로 작용해 오분류가 발생하고 있습니다.

### 1.4 카테고리 구조 간소화 방안의 효과

작성자는 이러한 문제를 해결하기 위해 분류 체계를 단순화하여 3가지로 통합하는 방안을 제안하고 있습니다. 즉: **1) 일반질문, 2) 데이터조회, 3) 도메인 전문질문(트러블슈팅 + 설치방법)**으로 구분하겠다는 것입니다. 이러한 구조적 단순화는 다음과 같은 긍정적 영향을 기대할 수 있습니다.

**첫째, LLM의 분류 정확도 향상입니다.** 범주 수를 줄이고 각 범주의 차이를 분명히 하면 모델이 혼동할 여지가 줄어듭니다. 이제 LLM은 *"이 질문이 일반적인 대화냐, 데이터질문이냐, 아니면 전문 도메인 질문이냐"*만 판단하면 되므로, 이전보다 결정 난이도가 낮아집니다. 특히 3번과 4번이 하나로 통합됨으로써, 모델이 헷갈려 하던 두 선택지가 하나로 합쳐져 오분류 가능성이 낮아집니다. 실제로 다단계 분류 대신 상위 레벨에서 뭉뚱그려 분류하는 계층적 분류(hierarchical classification) 접근이 복잡한 문제에서 성능을 높이는 것으로 알려져 있습니다. 이번 개편은 그와 유사하게, 먼저 도메인 여부만 판단하게 하여 1차 분류 정확도를 높이는 효과가 있습니다. 예컨대 "너는 누구니"는 도메인 질문이 전혀 아니므로 모델이 혼동 없이 일반질문으로 분류할 가능성이 높아집니다. (반면 기존에는 도메인 내 세부 유형이 아닐 경우 TS로 떨어지는 편향이 있었는데, 이제는 도메인 vs 비도메인 구분 자체는 명확하므로 이런 편향 완화가 기대됩니다.)

**둘째, 라우팅 로직 단순화 및 유지보수 용이성입니다.** 이전에는 4개의 경로를 관리하며 각기 다른 처리(지식베이스 쿼리, 답변 포맷 등)를 수행했다면, 이제 3개의 경로만 관리하면 됩니다. 특히 도메인 전문질문은 단일 파이프라인으로 합쳐지므로, 해당 경로의 설계와 최적화에 집중할 수 있습니다. 예를 들어 3+4번을 합친 도메인 경로에서, 질문이 설치 방법형인지 문제 해결형인지에 따라 세부 답변 스타일만 조절하면 일관된 하나의 knowledge base 검색 프로세스로 통일할 수 있습니다. (질문 내용에 "설치"나 "설정" 등이 있으면 답변을 절차 안내 형식으로, "오류"나 "문제" 등이 있으면 원인-대책 형식으로 서술하는 등 추가 분기 가능). 이러한 후처리 분기는 최종 답변 생성단계에서 충분히 판단할 수 있으므로, 굳이 최상위 라우팅을 두 갈래로 나눌 필요가 없던 것입니다. 따라서 상위 분류를 단순화해도 응답 품질은 유지되거나 향상될 수 있습니다. LLM은 질문 내용만으로도 그것이 문제 해결 질문인지 작업 안내 요청인지 상당 부분 파악할 수 있으므로, 통합 경로 내에서도 자연스럽게 적합한 어조와 내용을 생성할 것입니다.

**셋째, 분류 실수로 인한 치명적 오류 감소입니다.** 카테고리가 줄어들면 잘못된 분기로 갈 가능성 자체가 줄어들뿐 아니라, 설사 분류가 조금 부정확해도 큰 문제를 일으킬 확률이 낮습니다. 예를 들어 이전에는 설치질문을 TS로 잘못 분류하면 전혀 엉뚱한 종류의 답변이 나왔겠지만, 이제 설치질문과 TS질문이 같은 도메인 경로로 가기 때문에 설치 질문이 잘못 TS로 분류되는 경우 자체가 사라집니다(통합됐으므로). 즉 분류 오차에 대한 내성이 커지는 셈입니다. 남은 혼동 여지가 있다면 일반 vs 도메인의 구분인데, 이는 상대적으로 명확하며 만에 하나 도메인 질문을 일반으로 분류해버리더라도 일반 프롬프트로 어느 정도 답변을 시도할 수는 있을 것입니다. 전체적으로 에이전트 라우팅의 신뢰성과 안정성이 향상될 것으로 기대됩니다.

다만 유의할 점은, 기존에 3번과 4번에 대해 각기 최적화된 처리가 있었다면 이를 하나로 합치는 과정에서 세부 기능 조정이 필요합니다. 예를 들어 설치 방법 질문은 단순 절차 나열이면 충분하지만, 트러블슈팅은 원인 분석과 여러 해결책 비교가 필요할 수 있습니다. 통합 경로에서 이러한 세부 요구사항 차이를 다룰 수 있도록, 앞서 언급한 질문 의도에 따른 답변 템플릿 분기나 추론 과정의 조건부 로직을 구현해야 합니다. 또한 knowledge base도 통합된다면 문서 검색 시 설치 관련 문서와 문제 해결 문서를 모두 뒤져볼 텐데, 검색 결과에서 문맥을 잘 선별하도록 해야 합니다. (예: "설치" 키워드가 포함된 문서는 우선적으로 사용하거나 등등). 이러한 보완이 이뤄진다면 카테고리 간소화는 성능상의 부정적 영향 없이 긍정적 효과만 가져올 것으로 판단됩니다.

### 1.5 오분류 발생 원인 분석 (왜 "너는 누구니"가 TS로 분류됐나)

위 문제를 초래한 구체적인 원인을 시스템 및 프롬프트 설계 측면과 컨텍스트 처리 측면에서 더 짚어보겠습니다.

**1. 프롬프트 설계 및 LLM 응답 방식 문제:** 분류 프롬프트가 LLM에게 정확한 지시를 주지 못했거나, LLM의 출력 형식이 불완전하게 처리된 것으로 보입니다. 예를 들어 현재 프롬프트가 *"질문을 읽고 1~4 중 하나를 답하라"*고만 돼 있고 "1은 이런 거, 2는 이런 거…" 식의 충분한 예시가 없다면, 모델은 애매한 질문에 대해 임의로 추측할 수 있습니다. *"너는 누구니"*는 어느 카테고리에도 딱 들어맞지 않아 애매한 사례인데, 이때 모델이 규칙을 엄격히 따르지 않고 자기 나름대로 해석했을 가능성이 있습니다. 혹은, 앞서 언급했듯 출력에 **"TS"**라는 단어가 포함되는 식의 형식 오류/파싱 오류가 있었을 수도 있습니다. 이는 기술적인 버그로, 충분히 발생 가능성이 있습니다. 따라서 "너는 누구니" 오분류는 단순 실수 같지만, 그 배경에는 LLM 분류의 고질적 한계가 있습니다. LLM은 기본적으로 생성 모델이라 분류 태스크에 최적화되어 있지 않고, 출력이 미묘하게 틀릴 수 있기 때문입니다. Prompt 설계를 단단히 해서 *"오직 아래 중 하나의 단어만 답하라"*고 지시해야 하는데, 혹시 이 부분이 미흡했다면 모델이 자유응답을 하며 엉뚱한 결과를 내놓았을 수 있습니다.

**2. 도메인 맥락 과투입 및 역할 혼동:** 현재 에이전트의 시스템 프롬프트/페르소나가 **"반도체 문제 해결 도우미"**로 강하게 주어져 있으면, 모델은 사용자의 "너는 누구니" 질문을 받았을 때 일반적 호기심으로 보지 않고 도메인과 연결짓는 맥락 추론을 했을 수 있습니다. 예를 들어 "내가 누구인지 (이 시스템에서) 묻는다 = 사용자가 시스템 구조나 담당자를 물어보나?" 식으로 과대해석했을 수 있다는 겁니다. 이는 사람에게는 부자연스럽지만, 모델은 시스템 역할 지시에 충실하려다 보면 과도한 연관성을 부여하기도 합니다. 결과적으로 LLM은 "이 질문은 일반 대화라기보다, 시스템(나)에 대해 기술적으로 물어보는 걸지도 몰라" 하고 트러블슈팅 관련 문의로 잘못 분류했을 수 있습니다. 다시 말해, 에이전트 자신의 identity조차도 전문적인 설명 대상으로 간주한 셈입니다. 이러한 오류는 프롬프트에 일반적 대화나 메타질문 대응 규칙이 없을 때 발생하기 쉽습니다. 해결책은 앞서 제언했듯, 시스템 프롬프트에 일반 질문 예시를 포함하고 에이전트 본인에 대한 질문은 일반 대화로 처리하라는 지침을 넣는 것입니다. 또한 함수 호출 기능이 있다면 아예 get_agent_identity() 같은 함수를 일반질문 핸들러로 등록해 모델이 그 함수를 호출하게 하는 것도 방법입니다 – 이를 통해 모델이 이런 질문을 확실히 일반 영역으로 구분하도록 유도할 수 있습니다.

**3. 대화 컨텍스트 관리 문제:** 앞서 잠깐 언급한 대로, 이전 턴의 맥락이 분류에 악영향을 줬을 가능성이 큽니다. 만약 에이전트가 사용자와의 전체 대화 기록을 분류 모델 입력에 전부 사용하고 있었다면 문제입니다. 이상적인 의도 분류는 현재 사용자 메시지만으로 판단해야 하지만, 혹시 구현상 ChatGPT API 호출에 과거 대화 메시지도 함께 넣었다면, 모델은 현재 질문을 대화의 연속선상에서 해석해버립니다. 그래서 "너는 누구니"가 이전 TS 대화의 연장으로 오인되었을 확률이 있습니다. 이 경우 솔루션은 분류용 LLM 호출을 메인 대화와 분리하는 것입니다. 즉, 분류를 할 때는 별도의 시스템 메시지와 사용자 마지막 질문만 보내서 판단하게 하고, 라우팅 결정 후 비로소 해당 경로의 체인을 별도로 작동시키면 됩니다. 실제 OpenAI 개발자들도 멀티턴 대화에서는 대화 맥락이 의도 파악을 흐릴 수 있으므로, 필요하면 대화 컨텍스트를 생략하거나 감소시켜 모델이 현재 질문 자체에만 집중하도록 권장합니다. 현재 시스템이 이러한 분리 없이 한 세션으로 모든 것을 처리했다면, 구조를 분리하여 컨텍스트 혼입을 막아야 합니다.

요약하면 "너는 누구니" 오분류는 LLM 분류의 한계와 프롬프트 편향, 그리고 컨텍스트 관리 문제의 복합 결과입니다. 분류 기준에 맞지 않는 질문에 대한 예외 처리 부재, 도메인 중심 시스템 지시로 인한 편향, 대화 맥락 미분리가 합쳐져 발생한 것이죠.

### 1.6 개선 방향 및 권장 조치

위 진단을 바탕으로, 에이전트 라우팅 성능 향상을 위한 구체적인 개선 방향을 제시하면 다음과 같습니다:

**① 카테고리 체계 단순화 구현:** 우선 작성자 구상대로 라우팅 카테고리를 3가지(일반, 데이터조회, 도메인전문)로 통합하세요. 이를 통해 LLM의 판단부담을 줄이고 정확도를 높일 수 있습니다. 특히 도메인 전문질문은 하나로 묶어 1차 분류하고, 필요하면 도메인 경로 내부에서 질문 유형별 세부 로직을 추가 구현하면 됩니다. 예컨대 도메인 경로의 시스템 프롬프트에 "질문이 설치 방법 관련이면 단계별 가이드를, 장애/오류 관련이면 원인 진단과 조치를 설명해줘" 같은 지시를 조건부로 넣을 수 있습니다. 이렇게 계층적 접근을 취하면 분류 신뢰도가 높아지고도 최종 답변 품질을 유지할 수 있습니다.

**② 분류용 프롬프트 개선:** LLM에게 의도 분류를 시킬 때의 프롬프트 내용을 재점검해야 합니다. 가능한 한 명확하고 간결하게 지시하고, 각 카테고리에 대한 충분한 예시를 제공하세요. 예를 들어 시스템 메시지에: *"사용자의 질문을 읽고 '일반 대화', '데이터 질의', '전문 도메인 질문' 중 하나로 분류하세요. 아래는 각 범주의 설명과 예시입니다:"*라고 적고, 일반에는 ("오늘 기분 어때?" → 일반 대화), 데이터에는 ("지난주 생산량 알려줘" → 데이터 질의), 도메인에는 ("장비 X 온도오류 원인?" → 전문 도메인 질문) 등의 예시를 나열합니다. 그런 다음 *"출력은 오직 해당 범주의 이름만 답하세요."*라고 명시하면 모델 출력의 일관성을 강제할 수 있습니다. 또한 temperature는 0에 가깝게 낮춰서 확정적 답변을 유도하고, 최대 토큰도 아주 작게 제한해 불필요한 설명이 나오지 않게 합니다. 이러한 프롬프트 엔지니어링은 앞서 언급된 LLM 분류의 불안정성을 상당 부분 완화할 것입니다.

**③ 시스템 프롬프트의 범용성 확보:** 에이전트의 기본 시스템 메시지를 검토해 도메인 편향을 완화해야 합니다. 여전히 에이전트의 주된 역할은 전문 도메인 지원이지만, 일반적인 사용자 요청에도 적절히 답할 수 있도록 페르소나를 유연하게 설정하는 것이 좋습니다. 예를 들어 "당신은 반도체 공정 트러블슈팅 및 정보 제공을 돕는 AI 비서입니다. 질문의 종류에 따라, 일반적인 대화에는 친근하게 답변하고, 데이터 요청에는 정확한 수치를 제시하며, 전문 질문에는 관련 지식을 찾아 해결책을 제시합니다." 등으로 범위를 모두 언급해 둡니다. 이렇게 하면 모델이 사용자 질문의 맥락에 따라 자율적으로 모드를 전환하는 데 도움이 됩니다. 특히 자신의 정체를 묻는 질문에는 간략히 자기소개를 하면 된다는 식으로 언급해두면, "너는 누구니" 같은 질문에 과잉해석하지 않고 올바르게 반응할 것입니다.

**④ 대화 컨텍스트 처리 로직 개선:** 의도 분류 단계에서는 반드시 현재 메시지만 고려하도록 구현을 변경하세요. 만약 현 구조가 messages=[...{role: system,...}, {role: user, content: 이전질문}, {role: assistant, content: 이전답변}, {role: user, content: 새질문}] 식으로 모든 턴을 줬다면, 분류용 API 호출은 {role: system, content: 분류지침}, {role: user, content: 새질문} 두 개만 보내도록 해야 합니다. 이전 대화는 제외하거나, 혹은 정말 필요하면 user 메시지에 직전 질문 종류 태그 정도만 전달하는 방법도 있지만, 가급적 분류시에는 이전 맥락을 배제하는 것이 안전합니다. 그리고 일단 분류 결과가 나오면, 그에 맞는 체인을 선택해 별도의 대화 맥락으로 답변을 생성합니다. 이렇게 분류 단계와 답변 단계를 분리하면, 라우팅 결정이 이전 답변 내용에 영향받아 왜곡되는 일을 막을 수 있습니다.

또한 멀티턴 대화를 이어갈 때도 토픽 전환 감지가 필요합니다. 예를 들어 사용자가 연속으로 전문 질문을 하다가 갑자기 일반적인 질문을 하면, 에이전트는 이를 새로운 대화 주제로 인식해야 합니다. 이를 위해 분류 모델이 현재 질문이 이전 주제와 관련 있는지도 판단하도록 할 수 있습니다 (예: 프롬프트에 "만약 이전 대화 맥락과 관련된 후속 질문이면 같은 범주를 유지하고, 새 주제라면 재분류하라"는 지침 추가). 혹은 간단히, 일반질문으로 분류되면 컨텍스트 메모리를 초기화하는 정책을 세울 수도 있습니다. 이렇게 하면 도메인 대화 도중이라도 사용자가 "잠깐 딴 질문"을 했을 때 정확히 반응할 수 있습니다.

**⑤ 대안적인 라우팅 기법 고려:** 현재는 LLM에게 분류를 완전히 맡기고 있으나, 필요하다면 룰 기반 보조나 임베딩 기반 유사도 매칭 기법을 혼용할 수 있습니다. 예를 들어 "누구/몇/어떻게" 등 키워드로 1차 필터를 하거나, 대표 질의문들을 임베딩해 두고 코사인 유사도로 가장 가까운 의도를 찾는 방법도 있습니다. 실제로 한 사례에서는 의도 라우팅에 LLM 호출을 사용하지 않고 벡터 임베딩으로 수 ms 내에 실시간 분류함으로써 안정성과 속도를 높인 보고도 있습니다. 우리의 경우도 카테고리가 3개로 단순하므로, 임베딩을 써서 분류해도 정확도가 높게 나올 수 있습니다. 혹은 OpenAI의 함수 호출 기능을 이용해 각 카테고리에 대응하는 함수를 선언해두면, 모델이 적절한 함수를 골라 호출하도록 유도할 수도 있습니다. 이는 사실상 분류와 동일한 작업이지만, 모델이 함수 포맷에 맞춰 출력을 내놓으므로 파싱이 확실하고 잘못된 자유응답이 줄어드는 장점이 있습니다. 이러한 하이브리드 접근은 LLM 분류의 불확실성을 보완해 줄 수 있으니, 추후 성능 테스트를 통해 도입을 검토하시기 바랍니다.

**⑥ 로그와 피드백을 통한 지속적 개선:** 마지막으로, 실제 사용자 질문 로그를 모니터링하면서 분류 오류 사례를 수집하세요. "너는 누구니" 같은 오분류가 또 발생하면 해당 패턴을 프롬프트에 추가하거나 규칙 기반 예외처리를 넣고, 데이터 질의로 분류됐어야 할 것이 도메인으로 갔다면 그 질문을 토대로 분류 프롬프트를 보강하는 식입니다. LLM 기반 분류는 완벽하지 않으므로, 인적 피드백 루프를 통해 점진적으로 정확도를 높이는 것이 중요합니다. 특히 새로 통합된 도메인 카테고리가 너무 포괄적이라면, 도메인 내부에서 추가 질문을 던져 상세 의도를 파악하는 방법도 고려해볼 수 있습니다 (예: "이 질문은 오류 해결에 대한 것인지, 단순 정보 문의인지 추가로 알려주세요"라고 모델이 되물을 수도 있음). 사용자의 노력 없이도 답해야 한다면, 최대한 모델이 스스로 문맥에서 판별하도록 위의 조치들을 반복 개선해야 합니다.

### 1.7 결론

요약하면, 현 에이전트의 라우팅 전략에서는 LLM 의존 분류의 한계와 프롬프트 설계상의 빈틈으로 인해 일반 문의조차 잘못된 전문 경로로 라우팅되는 문제가 있었습니다. 이를 해결하기 위해 분류 체계를 단순화하여 모델의 혼란을 줄이고, 시스템 프롬프트를 재설계하며, 컨텍스트 관리 로직을 개선하는 것을 권장드립니다. 카테고리를 4개에서 3개로 통합하는 조치는 LLM 분류 정확도를 높이고 유지보수성을 향상시켜 줄 것으로 기대됩니다. 동시에 분류 프롬프트에 명확한 지침과 예시를 부여하고, 일반 대화에 대응하는 페르소나도 함께 주입함으로써 모델이 사용자 의도를 정확히 인지하도록 해야 합니다. 아울러 대화 이력 관리에도 신경 써서, 문맥으로 인한 오해를 최소화해야 합니다. 이러한 개선들을 적용하면, 에이전트는 "너는 누구니?" 같은 질문은 제대로 일반 질의로 처리하고, 도메인 관련 질문만 정확히 RAG 파이프라인을 타도록 라우팅 정확도와 신뢰성이 크게 향상될 것입니다. 필요에 따라 임베딩 기반 라우터 등도 활용하여 LLM의 약점을 보완하면, 더욱 견고한 멀티모달 에이전트로 거듭날 수 있을 것입니다.

---

## 2. 실제 코드와의 비교 분석

### 2.1 현재 코드 구조

실제 프로젝트의 라우팅 구조는 다음과 같습니다:

```yaml
# backend/llm_infrastructure/llm/prompts/router_v1.yaml
name: router
version: v1
description: Route user intent to setup / ts / general (semiconductor QA).
system: |
  # Role
  You are a routing agent that classifies semiconductor equipment Q&A
  into three categories: setup / ts / general.

  # Output Format
  - Output exactly ONE lowercase word from these labels: setup | ts | general
  - NO code blocks, explanations, quotes, or periods. Example: ts

  # Label Definitions
  - setup:
    - Installation, replacement, disassembly, assembly, initialization,
      calibration, settings, parameter/recipe configuration, checklists,
      cable connections, bring-up/setup procedures
  - ts:
    - Alarms/errors/warnings/interlocks/fail/abnormal symptoms,
      root cause/troubleshooting/log analysis/prevention
    - Follow-up questions about the same alarm/symptom
  - general:
    - General explanations, document overviews, company info, policies
      that don't clearly fit the above two categories

  # Priority (multiple intents)
  - ts > setup > general
  - If asking about both installation procedure and troubleshooting, choose ts.
```

### 2.2 문서와 실제 코드의 차이점

| 항목 | 문서의 가정 | 실제 코드 |
|------|------------|----------|
| **카테고리 수** | 4개 | **3개** |
| **카테고리** | 일반, 데이터조회, TS, 설치방법 | **setup, ts, general** |
| **데이터 조회** | 있음 | **없음 (향후 추가 예정)** |
| **프레임워크** | LangChain RouterChain | **LangGraph** |
| **컨텍스트 처리** | 전체 대화 포함 우려 | **query_en만 사용 (분리됨)** |

### 2.3 현재 코드에서 잘 되어 있는 부분

```python
# langgraph_agent.py:633-639
def route_node(state: AgentState, *, llm: BaseLLM, spec: PromptSpec) -> Dict[str, Any]:
    # Use English query for routing (after translation)
    query = state.get("query_en") or state["query"]  # ✅ 현재 쿼리만 사용
    user = _format_prompt(spec.router.user, {"sys.query": query})
    route = _parse_route(_invoke_llm(llm, spec.router.system, user))  # ✅ 파싱 함수 존재
    return {"route": route}
```

**이미 잘 구현된 것:**
- 컨텍스트 분리: 분류 시 `query_en`만 사용 (이전 대화 미포함)
- 출력 포맷 강제: `_parse_route()` 함수로 정규화
- 3개 카테고리 운영: setup / ts / general

---

## 3. 담당자 의견

### 3.1 문서 평가

| 항목 | 평가 | 비고 |
|------|------|------|
| LLM 분류 한계 분석 | ✅ 유효 | 일반적인 문제점 잘 지적 |
| 프롬프트 편향 지적 | ✅ 유효 | general 예시 부족 문제 |
| 카테고리 현황 파악 | ❌ 부정확 | 4개가 아닌 3개 운영 중 |
| 컨텍스트 관리 우려 | ⚠️ 부분 유효 | 현재 분리되어 있으나 확인 필요 |
| 개선 방향 | ✅ 유효 | 대부분 적용 가능 |

### 3.2 실제 적용 가능한 개선사항

#### 즉시 적용 가능

**1. router_v1.yaml의 general 카테고리 보강**

```yaml
# 현재
- general:
    - General explanations, document overviews, company info, policies
      that don't clearly fit the above two categories

# 개선안
- general:
    - General explanations, document overviews, company info, policies
    - Questions about the agent itself ("Who are you?", "What can you do?")
    - Casual conversation, greetings, off-topic questions
    - Anything that doesn't clearly fit setup or ts
```

**2. Few-shot 예시 추가**

```yaml
# Examples (추가)
- "How do I install sensor X?" → setup
- "Error E-001 keeps appearing" → ts
- "Who are you?" → general
- "너는 누구니?" → general
- "What is the company policy?" → general
```

#### 향후 고려사항

**1. 데이터 조회 카테고리 추가 시**
- 문서에서 제안한 계층적 분류 고려
- 1차: 도메인 vs 비도메인
- 2차: 세부 분류 (setup/ts/data)

**2. 임베딩 기반 라우팅**
- LLM 호출 비용/지연 감소
- 일관성 있는 분류 결과
- 카테고리가 늘어날 경우 특히 유효

**3. 하이브리드 접근**
- 키워드 기반 1차 필터 + LLM 2차 분류
- "누구", "뭐야" 등 패턴 → 바로 general

### 3.3 결론

문서의 분석은 LLM 기반 라우팅의 일반적인 한계를 잘 짚고 있으나, 현재 코드 구조에 대한 가정이 일부 부정확합니다.

**핵심 개선 포인트:**
1. `router_v1.yaml`의 general 카테고리에 일반 대화/에이전트 관련 질문 예시 추가
2. Few-shot 예시로 분류 정확도 향상
3. 향후 데이터 조회 추가 시 계층적 분류 또는 임베딩 기반 라우팅 검토

현재 구조에서 가장 효과적인 개선은 **프롬프트 보강**입니다. 다만 프롬프트 스펙이 캐시되므로, YAML 수정 후에는 서버 재시작 또는 캐시 무효화가 필요할 수 있습니다 (`backend/api/dependencies.py:176`).

---

## 4. Agent 구조 개선 권장사항 (추가 리뷰)

### 4.1 명시적 그래프 분기 사용 (Explicit Graph Branching)

#### 현재 설계

`route` 노드가 질문을 setup, ts, general로 분류한 후, 그래프는 분기하지 않습니다. 대신 후속 노드(mq_node, answer_node)에서 `state["route"]`를 사용해 if/elif 로직으로 적절한 프롬프트 템플릿을 선택합니다.

```python
# 현재 mq_node 내부 로직
if route == "setup":
    # use spec.setup_mq
elif route == "ts":
    # use spec.ts_mq
else:
    # use spec.general_mq
```

이 설계는 작동하지만, 분기 로직이 노드 구현에 혼재되어 있습니다.

#### 개선 제안

LangGraph의 조건부 엣지를 활용하여 route 분류에 따라 그래프를 명시적으로 분기:

```python
builder.add_node("setup_mq", wrapped_setup_mq_node)
builder.add_node("ts_mq", wrapped_ts_mq_node)
builder.add_node("general_mq", wrapped_general_mq_node)

builder.add_conditional_edges(
    "route",
    lambda st: st["route"],
    {"setup": "setup_mq", "ts": "ts_mq", "general": "general_mq"}
)
```

#### 기대 효과

| 항목 | 효과 |
|------|------|
| **명확성** | 그래프 시각화 및 로그에서 분기 경로가 직접 표시됨 |
| **모듈성** | 각 카테고리별 노드 구현을 독립적으로 수정 가능 |
| **확장성** | 새 카테고리 추가 시 노드 추가 + 매핑 조정으로 간단히 처리 |
| **상태 간소화** | 현재 3개의 MQ 리스트 중 2개는 항상 비어있음 → 불필요한 상태 제거 |

### 4.2 st_gate 및 st_mq 흐름 최적화

#### 현재 문제

현재 파이프라인은 모든 쿼리에 대해 항상 `st_gate → st_mq` 순서로 실행됩니다. `st_gate`가 "no_st" (특별 처리 불필요)를 반환해도 `st_mq`에서 LLM을 호출합니다.

#### 개선 제안

**방법 1: 그래프 분기**
```python
builder.add_conditional_edges(
    "st_gate",
    lambda st: st["st_gate"],
    {"need_st": "st_mq", "no_st": "retrieve"}
)
```

**방법 2: 노드 내 로직**
```python
def st_mq_node(state, ...):
    if state["st_gate"] == "no_st":
        # LLM 호출 없이 기존 쿼리를 search_queries로 병합
        return {"search_queries": merge_queries(state)}
    # need_st인 경우만 LLM 호출
    return _invoke_llm(...)
```

#### 적용 시 주의사항 (현재 코드 기준)

현재 `st_mq_node()`는 단순 통합 역할을 넘어서, 아래를 함께 수행합니다.

- bilingual 쿼리 보강 (EN/KO 각각 최소 3개 확보)
- KO 쿼리가 부족할 때 번역 프롬프트(`translate_v1.yaml`)로 보완
- 가비지 쿼리 필터링

따라서 **그래프에서 `st_mq`를 통째로 스킵**하면, 위 보강 로직까지 사라져 검색 품질이 떨어질 수 있습니다.

#### 안전한 적용안 (권장)

- `st_gate == "no_st"`일 때 **LLM 호출만 스킵**하고,
- 쿼리 병합/번역/필터링 로직은 그대로 수행하도록 `st_mq_node()` 내부 분기를 추가

#### 기대 효과

- 단순한 쿼리에서 불필요한 LLM 호출 제거
- 토큰 비용 및 지연 시간 절감

### 4.3 라우트 메타데이터를 활용한 타겟 검색

#### 제안 내용

이미 질문을 카테고리로 분류하고 있으므로, 이 정보를 검색 단계에서 활용:

| route | 검색 최적화 |
|-------|------------|
| **setup** | 설치 매뉴얼, 절차 문서 우선 검색 |
| **ts** | 트러블슈팅 가이드, 에러 로그, FAQ 우선 검색 |
| **general** | 정책 문서, 일반 설명 문서 검색 |

#### 구현 방법

- `doc_type` 필드 기반 부스팅 우선 적용 (하드 필터링은 리콜 손실 위험)
- 카테고리별 `top_k` 조정 (ts는 더 많은 문서 검색)
- SearchService에 `route` 기반 필터 파라미터 추가

### 4.4 프롬프트 관리 통합

#### 개선 제안

**1. Judge 프롬프트 외부화**

현재 코드 내 상수로 정의된 Judge 프롬프트를 YAML로 이동:

```yaml
# prompts/judge_setup_v1.yaml
name: judge_setup
system: |
  # 역할
  설치/세팅 답변이 질문과 검색 증거에 충실한지 판정한다.
  ...
```

**2. 언어 처리 간소화**

현재 언어별 별도 템플릿 (9개):
- setup_ans_v1.yaml, setup_ans_en_v1.yaml, setup_ans_ja_v1.yaml
- ts_ans_v1.yaml, ts_ans_en_v1.yaml, ts_ans_ja_v1.yaml
- general_ans_v1.yaml, general_ans_en_v1.yaml, general_ans_ja_v1.yaml

대안:
- 단일 언어로 생성 후 번역 단계 추가
- 또는 템플릿 파라미터화로 중복 감소

**3. YAML 앵커 활용**

공통 섹션이 있는 프롬프트는 YAML 앵커로 중복 제거

### 4.5 재시도 및 피드백 메커니즘 개선

#### 현재 구조

- Judge가 불충실 판정 시 3단계 재시도
- `max_attempts` 기본값 1 (최대 2번 시도)

#### 개선 제안

**1. 동적 재시도 횟수**

```python
# ts 질문은 더 어려울 수 있으므로 추가 재시도 허용
if state["route"] == "ts":
    max_attempts = 2
else:
    max_attempts = 1
```

**2. Judge 피드백 활용 강화**

현재 `hint`만 쿼리 개선에 사용. `issues` 목록도 답변 재생성 프롬프트에 포함:

```python
# 재시도 시 answer 프롬프트에 추가
"Note: 이전 답변의 문제점 - {issues}. 이를 해결해주세요."
```

### 4.6 성능 및 확장성 고려사항

#### 1. 독립 단계 병렬화

다중 검색 쿼리 실행 시 병렬 처리:

```python
# 현재: 순차 실행
for query in search_queries:
    results.extend(search_service.search(query))

# 개선: 비동기 병렬 실행
async def parallel_search(queries):
    tasks = [search_service.search_async(q) for q in queries]
    return await asyncio.gather(*tasks)
```

#### 2. 노드별 모델 선택

| 노드 | 권장 모델 | 이유 |
|------|----------|------|
| route_node | 경량 모델 (GPT-3.5) | 단순 분류 작업 |
| judge_node | 경량 모델 (GPT-3.5) | 짧은 텍스트 평가 |
| answer_node | 고성능 모델 (GPT-4) | 복잡한 답변 생성 |

#### 3. 캐싱

동일/유사 질문에 대한 캐싱:

- route_node 결과 캐싱
- mq_node 결과 캐싱
- 프롬프트 버전 변경 시 캐시 무효화

### 4.7 RAGAS 진단 결과 반영 (Faithfulness 중심)

`docs/2026-01-27_ragas_diagnostic_report.md`에 따르면, 현재 가장 취약한 지표는 **Faithfulness(~0.36)**이며, Context Precision도 불안정합니다.

이 관점에서 보면, 라우팅 정확도 개선과 별개로 아래 항목의 우선순위를 올리는 것이 타당합니다.

#### 즉시 효과가 큰 보완 포인트

- 답변 프롬프트(`*_ans_*.yaml`)에 “문맥(REFS)에 없는 수치/고유명사/절차는 단정하지 말 것”을 더 강하게 명시
- 문맥이 약하거나 없는 경우의 **No Answer 정책**을 명시적으로 통일
- `st_gate_v1.yaml`에 모호/광범위 요청(예: “GCB 기반 정리”, “이력 정리”)에 대한 few-shot 예시 추가

#### 구조 개선 제안과의 연결

- `st_gate → st_mq` 최적화는 비용 절감에는 유리하지만, Faithfulness 개선에는 직접 효과가 제한적일 수 있음
- 반면, 답변 프롬프트 가드레일과 No Answer 정책은 Faithfulness 저하(할루시네이션) 문제에 직접 대응
- route 메타데이터를 검색 부스팅에 활용하는 제안은 Context Precision 개선과 연결됨 (하드 필터보다 부스팅 우선 권장)

---

## 5. 종합 의견 및 권장사항

### 5.1 문서 평가 요약

| 문서 | 핵심 내용 | 유효성 | 비고 |
|------|----------|--------|------|
| **1차 진단 문서** | 라우팅 오분류 분석 | ⚠️ 부분 유효 | 카테고리 수 가정 오류 |
| **2차 구조 개선 문서** | 그래프 분기, 최적화 | ✅ 유효 | 대부분 적용 가능 |
| **RAGAS 진단 보고서** | Faithfulness/검색 품질 이슈 | ✅ 매우 유효 | 우선순위 재조정 필요 |

### 5.2 우선순위별 권장 조치

#### 즉시 적용 (Low Effort, High Impact)

| 순위 | 조치 | 영향 | 난이도 |
|------|------|------|--------|
| 1 | **답변 프롬프트 근거 제한 강화** (`*_ans_*.yaml`) | Faithfulness 향상 | ⭐ |
| 2 | **No Answer 정책 명시/통일** | 할루시네이션 감소 | ⭐⭐ |
| 3 | **router_v1.yaml general 예시 + few-shot 보강** | 라우팅 오분류 감소 | ⭐ |
| 4 | **st_gate few-shot 예시 추가** | 모호한 질문 처리 개선 | ⭐⭐ |

#### 단기 개선 (Medium Effort)

| 순위 | 조치 | 영향 | 난이도 |
|------|------|------|--------|
| 5 | **st_gate=no_st 시 LLM 호출만 스킵** | 비용/지연 감소 (품질 보존) | ⭐⭐ |
| 6 | **route 메타데이터 → 검색 부스팅** | Context Precision 향상 | ⭐⭐ |
| 7 | **Judge 프롬프트 YAML 이동** | 유지보수성 향상 | ⭐⭐ |
| 8 | **refine_queries 활용 강화** (hint+issues 실험) | 재시도 효과 개선 | ⭐⭐ |

#### 장기 고려 (High Effort)

| 순위 | 조치 | 영향 | 난이도 |
|------|------|------|--------|
| 9 | **노드별 모델 분리** | 비용 최적화 | ⭐⭐⭐ |
| 10 | **검색 병렬화** | 지연 시간 감소 | ⭐⭐⭐ |
| 11 | **임베딩 기반 라우팅** | 일관성/속도 향상 | ⭐⭐⭐ |
| 12 | **데이터 조회 카테고리 추가** | 기능 확장 | ⭐⭐⭐ |
| 13 | **골든셋 기반 평가 체계 구축** | 정확한 성능 측정 | ⭐⭐⭐ |

### 5.3 구조 개선에 대한 의견

#### 명시적 그래프 분기 (제안 1)

**찬성:**
- 그래프 시각화/디버깅 용이
- 카테고리별 독립적 수정 가능

**우려:**
- 현재 구조도 잘 작동함
- 노드 수 증가로 복잡도 상승 가능
- 공통 로직 중복 발생 가능

**결론:** 현재 규모에서는 선택 사항. 카테고리가 4개 이상으로 늘어나면 적용 권장.

#### st_gate 최적화 (제안 2)

**강력 권장.** 불필요한 LLM 호출 제거는 명확한 이점이다. 다만 `st_mq` 전체 스킵은 bilingual 보강/번역/필터링까지 빠질 수 있으므로, **no_st에서 LLM 호출만 스킵**하는 방식이 안전하다.

#### 노드별 모델 분리 (제안 6)

**검토 필요.** 비용 절감 효과는 있으나:
- 모델 품질 차이로 인한 정확도 하락 위험
- 인프라 복잡도 증가
- 실제 비용 대비 효과 측정 필요

### 5.4 최종 결론

1. **즉시 적용**: Faithfulness 개선에 직결되는 프롬프트 가드레일(답변/No Answer) 우선 보강
2. **단기 적용**: st_gate/st_mq 최적화는 “LLM 호출만 스킵” 방식으로 안전하게 적용
3. **단기 적용**: route 메타데이터는 하드 필터보다 “검색 부스팅”부터 적용
4. **장기 검토**: 명시적 분기, 모델 분리, 임베딩 라우팅, 골든셋 기반 평가 체계

현재 구조는 기본적으로 잘 설계되어 있으며, **프롬프트 수준의 개선**으로 대부분의 오분류 문제를 해결할 수 있습니다. 구조적 변경은 규모 확장 시 검토하는 것이 효율적입니다.
