# RAG Agent 대화 히스토리 및 문서 조회 개선 제안서

> 작성일: 2026-01-29
> 목적: 시니어 검토용 기술 제안서

---

## 1. 문제 정의

### 1.1 핵심 문제

현재 RAG Agent는 **대화의 맥락을 유지하지 못하고**, 사용자가 이전에 참조한 문서를 다시 조회하려면 **불필요한 검색 과정을 반복**해야 합니다.

### 1.2 구체적인 문제 상황

| 문제 | 설명 | 영향 |
|------|------|------|
| **대화 히스토리 미전달** | 각 요청이 독립적으로 처리됨 | 후속 질문 맥락 이해 불가 |
| **문서 재조회 비효율** | "그 문서에서..." 질문 시 처음부터 검색 | 속도 저하, 토큰 낭비 |
| **직접 문서 지정 불가** | "myservice 29392 설명해줘" 처리 불가 | 사용자 경험 저하 |

---

## 2. 현재 시스템 분석

### 2.1 기존 Agent 구조

```
┌─────────────────────────────────────────────────────────────┐
│                     현재 RAG Agent 플로우                      │
└─────────────────────────────────────────────────────────────┘

User Query
    │
    ▼
┌─────────────┐
│ auto_parse  │ ← 장비명/문서타입 추출 (현재: 규칙 기반만 사용)
└─────────────┘
    │
    ▼
┌─────────────┐
│   router    │ ← setup / ts / general 분류
└─────────────┘
    │
    ▼
┌─────────────┐
│  MQ 생성    │ ← Multi-Query 생성 (LLM 호출)
└─────────────┘
    │
    ▼
┌─────────────┐
│  retrieve   │ ← ES 검색 (top_k=50)
└─────────────┘
    │
    ▼
┌─────────────┐
│   rerank    │ ← 상위 10개 선정
└─────────────┘
    │
    ▼
┌─────────────┐
│   answer    │ ← LLM 답변 생성
└─────────────┘
    │
    ▼
┌─────────────┐
│   judge     │ ← 답변 충분성 평가
└─────────────┘

※ 참고: 일반 대화는 별도 `chat_answer` 경로로 RAG를 우회함 (이미 구현됨).
```

### 2.2 기존 구조의 한계

#### (1) 대화 히스토리 부재

```python
# 현재 AgentState - chat_history 필드 없음
class AgentState(TypedDict, total=False):
    query: str
    route: Route
    # ... (대화 히스토리 관련 필드 없음)
```

**결과:**
- 매 요청이 독립적으로 처리
- "아까 말한 것 더 자세히" 같은 후속 질문 처리 불가
- LLM이 이전 맥락을 알 수 없음

#### (2) 모든 질문이 동일한 검색 파이프라인 통과

```
"SUPRA XP 센서 이상"     → MQ 생성 → 검색 → 답변  (적절)
"그 문서에서 더 자세히"   → MQ 생성 → 검색 → 답변  (비효율)
"myservice 29392 설명해줘" → MQ 생성 → 검색 → 답변  (불필요)
```

**문제점:**
- 이미 doc_id를 알고 있는 경우에도 MQ 생성 → 검색 과정 수행
- 불필요한 LLM 호출 (MQ 생성)
- 검색 정확도 저하 (이미 특정된 문서를 다시 검색)

#### (3) 토큰 사용량 비효율

| 항목 | 현재 | 문제 |
|------|------|------|
| MQ 생성 | 매번 호출 | 문서 지정 시 불필요 |
| 검색 | 매번 전체 검색 | doc_id 직접 조회 가능 |
| 답변 생성 | 맥락 없음 | 같은 설명 반복 필요 |

---

## 3. 제안하는 해결책

### 3.1 개선 목표

1. **대화 맥락 유지**: 이전 Q/A와 참조 문서 정보 전달
2. **문서 직접 조회**: doc_id 기반 빠른 조회 경로 추가
3. **토큰 효율화**: 불필요한 LLM 호출 최소화

### 3.2 개선된 Agent 구조

```
┌─────────────────────────────────────────────────────────────┐
│                    개선된 RAG Agent 플로우                     │
└─────────────────────────────────────────────────────────────┘

User Query + Chat History
    │
    ▼
┌─────────────┐
│ auto_parse  │ ← 장비명/문서타입 추출 (현재: 규칙 기반만 사용)
└─────────────┘
    │
    ▼
┌─────────────┐     ┌─────────────────────────────────┐
│   router    │ ──▶ │ doc_lookup 판단 (NEW)           │
└─────────────┘     │  1. Rule: "myservice 29392" 패턴 │
    │               │  2. LLM: "그 문서에서..." 의도   │
    │               └─────────────────────────────────┘
    │
    ├─── doc_lookup ───┐
    │                  ▼
    │          ┌─────────────┐
    │          │ doc_id 추출 │ ← 쿼리 또는 history에서
    │          └─────────────┘
    │                  │
    │                  ▼
    │          ┌─────────────┐
    │          │ ES 직접조회 │ ← MQ 생략, doc_id로 조회
    │          └─────────────┘
    │                  │
    │                  ▼
    │          ┌─────────────┐
    │          │   answer    │
    │          └─────────────┘
    │
    └─── setup/ts/general ───▶ (기존 플로우 유지)
                               MQ → retrieve → rerank → answer

    ※ 일반 대화는 별도 `chat_answer` 경로로 바로 응답 (RAG 우회).
```

### 3.3 대화 히스토리 구조

```python
chat_history = [
    {
        "role": "user",
        "content": "SUPRA XP 센서 이상 해결 방법"
    },
    {
        "role": "assistant",
        "summary": "센서 이상 시 캘리브레이션 확인, 케이블 점검 필요",  # 답변 요약 (truncate)
        "refs": ["SUPRA XP 센서 TS", "Calibration SOP"],  # 문서 title (프롬프트용)
        "doc_ids": ["ts_001", "sop_002"]  # 문서 ID (재조회용)
    },
    {
        "role": "user",
        "content": "캘리브레이션은 어떻게 해?"
    }
]
```

**설계 원칙:**
- `summary`: 답변 앞 100~150자 truncate (LLM 요약 없이 시작)
- `refs`: 문서 title만 (토큰 절약)
- `doc_ids`: 저장용 포인터 (프롬프트에 포함 안함)

### 3.4 doc_lookup 라우트 판단 로직

```
┌─────────────────────────────────────────────────────────┐
│                  doc_lookup 판단 플로우                   │
└─────────────────────────────────────────────────────────┘

[1] Rule 기반 1차 체크 (빠름, LLM 호출 없음)
    │
    ├─ 패턴 매칭: "myservice 29392", "gcb 12345" 등
    │  → doc_lookup 확정
    │
    └─ 매칭 실패 → [2]로 진행

[2] LLM 기반 판단 (정확, 암묵적 참조 감지)
    │
    ├─ "그 문서에서...", "아까 말한...", "더 자세히"
    │  → doc_lookup (source: history)
    │
    └─ 새로운 검색 의도
       → 기존 라우트 (setup/ts/general)

[3] doc_id 검증
    │
    ├─ ES에 존재 → 조회 진행
    │
    └─ 존재 안함 → fallback (기존 MQ 검색)
```

**구현 힌트(기존 코드 활용):**
- `selected_doc_ids`를 채우면 `retrieve_node`에서 doc_id 필터링이 이미 동작함.
- 즉 doc_lookup_node가 doc_id를 추출해 `selected_doc_ids`로 전달하면
  **새로운 ES 조회 로직 없이 최소 구현** 가능.

---

### 3.5 History 전달 주체 명시 (구현 범위 확정용)

두 가지 중 하나를 선택해야 구현 범위가 명확해짐.

1. **클라이언트 전달 방식**: frontend가 chat_history를 매 요청에 포함
2. **서버 로딩 방식**: session_id로 backend가 history를 조회 후 주입

---

### 3.6 Title 없는 문서 대응 규칙

- title이 없는 경우:
  1. `doc_id`에서 의미 추출 (prefix, 패턴 기반)
  2. content 앞부분 1~2줄 snippet을 title 대체로 사용

---

## 4. 기대 효과

### 4.1 성능 개선

| 시나리오 | 현재 | 개선 후 | 효과 |
|----------|------|---------|------|
| 문서 재조회 | MQ + 검색 + rerank | doc_id 직접 조회 | **~70% 속도 향상** |
| 후속 질문 | 맥락 없이 새 검색 | history 기반 답변 | **정확도 향상** |
| 직접 문서 지정 | 처리 불가 | 즉시 조회 | **UX 개선** |

### 4.2 토큰 절약

| 항목 | 현재 | 개선 후 |
|------|------|---------|
| MQ 생성 | 매번 호출 | doc_lookup 시 생략 |
| History 전달 | 없음 | 요약 + title만 (경량) |
| 검색 결과 | 매번 새로 전달 | 이전 결과 재활용 |

### 4.3 사용자 경험 개선

**Before:**
```
User: "SUPRA XP 센서 이상"
Agent: (검색 → 답변) "센서 이상 시 calibration을 확인하세요..."

User: "calibration 방법 자세히"
Agent: (새로 검색 → 다른 문서 → 다른 답변) "Calibration이란..."
       ❌ 이전 맥락과 단절
```

**After:**
```
User: "SUPRA XP 센서 이상"
Agent: (검색 → 답변) "센서 이상 시 calibration을 확인하세요..."
       [참조: ts_001, sop_002]

User: "calibration 방법 자세히"
Agent: (history에서 doc_id 추출 → 직접 조회 → 답변)
       "앞서 언급한 문서에 따르면, calibration 절차는..."
       ✅ 이전 맥락 유지
```

---

## 5. 구현 범위

### 5.1 변경 대상

| 파일 | 변경 내용 |
|------|----------|
| `langgraph_agent.py` | AgentState에 chat_history 필드 추가 |
| `langgraph_agent.py` | doc_lookup 라우트 판단 로직 추가 |
| `langgraph_agent.py` | doc_lookup_node 구현 |
| `langgraph_rag_agent.py` | 그래프에 doc_lookup 노드/엣지 추가 |
| `agent.py` (router) | API에서 chat_history 수신/전달 |

### 5.2 구현 단계

| 단계 | 내용 | 예상 복잡도 |
|------|------|------------|
| 1 | AgentState에 chat_history 추가 | 낮음 |
| 2 | API에서 history 수신/응답에 포함 | 낮음 |
| 3 | doc_lookup rule 기반 판단 | 낮음 |
| 4 | doc_lookup LLM 기반 판단 | 중간 |
| 5 | doc_lookup_node 구현 | 중간 |
| 6 | fallback 로직 추가 | 낮음 |

---

## 6. 리스크 및 대응

| 리스크 | 영향 | 대응 방안 |
|--------|------|----------|
| LLM이 잘못된 doc_id 생성 | 조회 실패 | ES 검증 + fallback |
| History가 길어지면 토큰 증가 | 비용 증가 | 최근 N턴만 유지 + 요약 |
| doc_lookup 판단 오류 | 잘못된 경로 | fallback으로 기존 검색 수행 |

---

## 7. 결론

### 7.1 요약

현재 RAG Agent는 대화 맥락을 유지하지 못하고, 모든 질문에 동일한 검색 파이프라인을 적용하여 비효율이 발생합니다.

**제안하는 개선:**
1. **대화 히스토리 도입**: Q/A 요약 + 참조 문서 title/doc_id 전달
2. **doc_lookup 라우트 추가**: 문서 직접 조회 경로로 MQ 생략
3. **하이브리드 판단**: Rule 1차 + LLM 2차로 효율과 정확도 확보

### 7.2 검토 요청 사항

1. 대화 히스토리 구조 (summary + refs + doc_ids) 적절성
2. doc_lookup 라우트 분리 방식의 타당성
3. Rule + LLM 하이브리드 판단 방식 의견
4. 구현 우선순위 및 단계별 진행 방식

---

## 부록: 관련 코드 참조

- `backend/llm_infrastructure/llm/langgraph_agent.py`: AgentState, auto_parse_node, router
- `backend/services/agents/langgraph_rag_agent.py`: 그래프 빌드, 노드 연결
- `backend/api/routers/agent.py`: API 엔드포인트, AgentResponse
